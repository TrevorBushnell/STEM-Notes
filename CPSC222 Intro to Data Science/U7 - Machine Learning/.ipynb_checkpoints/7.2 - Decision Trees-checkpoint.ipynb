{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-Up Task\n",
    "\n",
    "* Load the 18 entries of shirt sizes into a DataFrame and min-max it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset:\n",
      "     height(cm)  weight(kg)\n",
      "0          158          58\n",
      "1          158          59\n",
      "2          158          63\n",
      "3          160          59\n",
      "4          160          60\n",
      "5          163          60\n",
      "6          163          61\n",
      "7          160          64\n",
      "8          163          64\n",
      "9          165          61\n",
      "10         165          62\n",
      "11         165          65\n",
      "12         168          62\n",
      "13         168          63\n",
      "14         168          66\n",
      "15         170          63\n",
      "16         170          64\n",
      "17         170          68\n",
      "\n",
      "training y-vector:\n",
      " 0     M\n",
      "1     M\n",
      "2     M\n",
      "3     M\n",
      "4     M\n",
      "5     M\n",
      "6     M\n",
      "7     L\n",
      "8     L\n",
      "9     L\n",
      "10    L\n",
      "11    L\n",
      "12    L\n",
      "13    L\n",
      "14    L\n",
      "15    L\n",
      "16    L\n",
      "17    L\n",
      "Name: t-shirt size, dtype: object\n",
      "\n",
      "test data:\n",
      " [[161, 63]]\n",
      "Normalized training data:\n",
      " [[0.         0.        ]\n",
      " [0.         0.1       ]\n",
      " [0.         0.5       ]\n",
      " [0.16666667 0.1       ]\n",
      " [0.16666667 0.2       ]\n",
      " [0.41666667 0.2       ]\n",
      " [0.41666667 0.3       ]\n",
      " [0.16666667 0.6       ]\n",
      " [0.41666667 0.6       ]\n",
      " [0.58333333 0.3       ]\n",
      " [0.58333333 0.4       ]\n",
      " [0.58333333 0.7       ]\n",
      " [0.83333333 0.4       ]\n",
      " [0.83333333 0.5       ]\n",
      " [0.83333333 0.8       ]\n",
      " [1.         0.5       ]\n",
      " [1.         0.6       ]\n",
      " [1.         1.        ]]\n",
      "\n",
      "Normalized test data:\n",
      " [[0.25 0.5 ]]\n",
      "y predicted: ['L']\n",
      "nearest neighbors: (array([[0.13017083, 0.19436506, 0.25      ]]), array([[7, 8, 2]], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('shirt_sizes_long.csv')\n",
    "\n",
    "X_train = df.drop(\"t-shirt size\", axis=1) # 1 is for columns\n",
    "print('training dataset:\\n', X_train)\n",
    "\n",
    "y_train = df[\"t-shirt size\"]\n",
    "print('\\ntraining y-vector:\\n', y_train)\n",
    "\n",
    "X_test = [[161, 63]]\n",
    "print('\\ntest data:\\n', X_test)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_normalized = scaler.transform(X_train)\n",
    "print('Normalized training data:\\n', X_train_normalized)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "print('\\nNormalized test data:\\n', X_test_normalized)\n",
    "\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_clf.fit(X_train_normalized, y_train)\n",
    "\n",
    "\n",
    "y_predicted = knn_clf.predict(X_test_normalized)\n",
    "print('y predicted:', y_predicted)\n",
    "print('nearest neighbors:', knn_clf.kneighbors(X_test_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Evaluation\n",
    "\n",
    "* In our previous demo, we had 1 instance in our \"test set\"\n",
    "    * If our classifier predicted this instance's class correctly, accuuracy 100%\n",
    "    * If our classifier predicted this instance's class incorrectly, accuracy 0%\n",
    "* Notes\n",
    "    * We should use a large test set to get a better picture\n",
    "    * Accuracy doesn't tell the whole story...\n",
    "        * E.g. 100 samples... 99 M, 1 L\n",
    "        * Classifier only predicts M\n",
    "        * We have 99% accuracy woohoo!!!\n",
    "        * **ACCURACY ONLY MAKES SENSE WHEN YOUR CLASS LABELS ARE NEAR EVENLY DISTRIBUTED**\n",
    "* Given a dataset, we need a way to \"divide\" our dataset into a training set and a test set\n",
    "    * A few ways to do this...\n",
    "        1. Hold out method\n",
    "        1. Random subsampling\n",
    "        1. Cross validation\n",
    "        1. Bootstrap method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout Method\n",
    "\n",
    "* \"hold out\" a certain number or percentage of instances in a dataset for testing\n",
    "   * Train on the remaining instances\n",
    "    * Typically choose a standard split or percentage\n",
    "        * E.G.: With a 2:1 split you have 1/3 data for testing and 2/3 data for training\n",
    "        * E.G.: 25% held out for testing, so remaining 75% is used for training\n",
    "            * Default for sklearn's `train_test_split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L' 'L' 'M' 'M' 'L']\n",
      "['L', 'M', 'L', 'M', 'L']\n",
      "0.6\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df.drop(\"t-shirt size\", axis=1)\n",
    "y = df[\"t-shirt size\"]\n",
    "\n",
    "# random state used for reproducability\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(\"t-shirt size\", axis=1), df[\"t-shirt size\"], random_state=0, stratify=df[\"t-shirt size\"])\n",
    "# print(X_train)\n",
    "# print(X_test)\n",
    "# print(y_train)\n",
    "# print(y_test)\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_predicted = knn_clf.predict(X_test)\n",
    "print(y_predicted)\n",
    "print(list(y_test))\n",
    "print(accuracy_score(y_test, y_predicted))\n",
    "print(knn_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L' 'M' 'L' 'M' 'L']\n",
      "['L', 'M', 'L', 'M', 'L']\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_predicted = tree_clf.predict(X_test)\n",
    "print(y_predicted)\n",
    "print(list(y_test))\n",
    "print(tree_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Subsampling\n",
    "\n",
    "Perform the hold out method $k$ times (different $k$ from kNN). Your accuracy is the mean accuracy over the $k$ runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "* With random subsampling, we are not guaranteed that each isntance ends up in a test set at least once\n",
    "* With cross validation, we are more intentional about our \"partitions\"\n",
    "* Algorithm:\n",
    "    * Divide the dataset into $k$ folds (yet another different $k$)\n",
    "    * For each fold:\n",
    "        * Hold out the fold and test on it\n",
    "        * Train on the remaining folds (folds - fold)\n",
    "* With this algorithm, each instance is tested exactly 1 time\n",
    "* Accuracy = total predicted correctly / total predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "[0.75       0.5        1.         0.66666667 0.66666667]\n",
      "['M' 'M' 'M' 'M' 'M' 'L' 'L' 'M' 'L' 'M' 'M' 'L' 'L' 'L' 'L' 'L' 'L' 'L']\n",
      "0.7222222222222222\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "[0.5        0.5        1.         1.         0.66666667]\n",
      "['M' 'M' 'L' 'M' 'M' 'M' 'L' 'M' 'M' 'M' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L']\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "# run 5-fold cross validation for both the knn and tree\n",
    "for clf in [knn_clf, tree_clf]:\n",
    "    print(type(clf))\n",
    "\n",
    "    # lazy approach\n",
    "    accuracies = cross_val_score(clf, X, y, cv=5)\n",
    "    print(accuracies)\n",
    "\n",
    "    # better approach\n",
    "    y_predicted = cross_val_predict(clf, X, y, cv=5)\n",
    "    print(y_predicted)\n",
    "    accuracy = accuracy_score(y, y_predicted)\n",
    "    print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9db6f3136cdaad7b22d0fc35b809682a07937f7d7bb3ba0ada81a46926793cc1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
