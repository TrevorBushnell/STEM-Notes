{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1: Intro and kNN Classifiers\n",
    "\n",
    "* Labeled data: the dataset has an attribute (column/variable that is typically called the class attribute) that you are interested in *predicting* for *unseen* instances (rows)\n",
    "* If you have labeled data, then you can do **supervised machine learning**\n",
    "* If your attribute is categorical, then the supervised ML is a *classification task*\n",
    "* If your attribute is numeric, then the supervised ML is a *regression task*\n",
    "* Unlabeled data: the dataset has no such attribute you want to predict\n",
    "* If you have unlabeled data, then you can do **unsupervised machine learning** (will be covered with the last unit in the class)\n",
    "\n",
    "## The Game Plan for the Rest of the Course\n",
    "\n",
    "**SUPERVISED ML ALGORITHMS**\n",
    "\n",
    "* Simple linear regression classifier (regression + discretization)\n",
    "* Simple kNN classifier\n",
    "* Simple dummy classifier\n",
    "* Naive Bayes classifier (PA6)\n",
    "* decision tree classifier (PA7)\n",
    "* random forest classifier (ensemble method) (project)\n",
    "\n",
    "\n",
    "**UNSUPERVISED ML ALGORITHMS**\n",
    "* association rule miner (PA8)\n",
    "* k means cluster (PA9) $\\to$ BONUS????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Example\n",
    "\n",
    "Linear regression follows this equation:\n",
    "\n",
    "$$\n",
    "y = mx + b\n",
    "$$\n",
    "* $m$ = slope\n",
    "* $b$ = y-intercept\n",
    "* $m$ and $b$ are \"learned\" from a training set\n",
    "* you evaulate how good that model is on a testing set\n",
    "\n",
    "TEST SET: `[150]`  \n",
    "* This means that we are predicting $y$ for $x = 150$  \n",
    "* $\\hat y = m(150) + b$  \n",
    "* y actual = 300  \n",
    "* $error = \\hat y - y_{actual}$\n",
    "\n",
    "our goal is to \"convert\" $y = mx + b$ into a standard API. Starting with PA4, we will start to invent ML algorithms that follow this API\n",
    "\n",
    "\n",
    "### Common API Terms\n",
    "\n",
    "* $X$: 2D feature matrix (e.g. table with features for columns) with $\\vec y$ removed\n",
    "* $\\vec y$: 1D class vector (e.g. the attribute/feature that you want to predict)\n",
    "    * Note: $X$ and $y$ are parallel!\n",
    "* we build a model/algorithm on \"training data\"\n",
    "* we evaluate a model/algorithm on \"testing data\"\n",
    "* This means that we split $X$ and $\\vec y$ into training and testing data\n",
    "* $X_{train}$: Testing data matrix\n",
    "* $\\vec y_{train}$: Testing class vector\n",
    "* $X_{test}$: Training data matrix\n",
    "* $\\vec y_{test}$: Training class vector\n",
    "* Each algorithm will be implemented as a class\n",
    "* Each class will have the same \"public\" API\n",
    "* `fit(X_train, y_train) -> None`\n",
    "    * \"fits\"  a model/trains an algorithm based on the provided training data\n",
    "* `predict(X_test) -> y_predicted(list)`\n",
    "    * makes predictions for each instance in `X_test`\n",
    "* we can compare `y_precicted` and `y_test` to see how well this model did on this particular test set\n",
    "    * for regression: MAE (average absolute differences between $y_{predicted}$ and $y_{test}$)\n",
    "* classification: accuracy (# matches between $y_{predicted}$ and $y_{test}$ divided by the total predictions)\n",
    "\n",
    "\n",
    "TASK FOR NEXT CLASS: Check out `mysimplelinearregressor.py`\n",
    "* This includes our work with `compute_linear_regression()` refactored with this API design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-Up Task 2/17/22 - Setting Up This Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[293.94940496062173]\n"
     ]
    }
   ],
   "source": [
    "from mysimplelinearregressor import MySimpleLinearRegressor\n",
    "import importlib\n",
    "import numpy as np\n",
    "importlib.reload(mysimplelinearregressor)\n",
    "np.random.seed(0)\n",
    "\n",
    "X_train = [[val] for val in range(100)]\n",
    "y_train = [row[0] * 2 + np.random.normal(0,25) for row in X_train] # 1D\n",
    "\n",
    "X_test = [[150]] # 2D\n",
    "\n",
    "lin_reg = MySimpleLinearRegressor()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_predicted = lin_reg.predict(X_test)\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take the example above and convert it into unit tests of `fit()` and `predict()`. You can check the `test_mysimplelinearregressor.py` in this directoy. \n",
    "\n",
    "Some tips for writing some test cases:\n",
    "\n",
    "* Start with simple/common test cases\n",
    "* Then move on to complex/edge test cases"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a707b6ce8c685eb936424fcc3009d4b4b7a52543c4db09380a3fc49186ceb509"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
