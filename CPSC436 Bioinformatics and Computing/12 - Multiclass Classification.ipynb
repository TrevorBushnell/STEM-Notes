{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture #12: Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Multiclass\n",
    "\n",
    "* Normally, we are used to dealing with logistic regression which lets us deal with binary classification\n",
    "* However, in the real world there are many instances where you can classify an instance with more than 2 possible classes\n",
    "  * i.e. there are multiple classes that we can put an instance into when we make a prediction, hence *multiclass*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Softmax - Generalization of Logistic Regression\n",
    "\n",
    "Recall that in logistic regression we had the following:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "z &= \\vec w \\cdot \\vec x + b\\\\\n",
    "a_1 &= g(z) = \\frac{1}{1+e^{-z}} = P(y=1|\\vec x)\\\\\n",
    "a_2 &= 1 - a_1 = P(y=0|\\vec x)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "In softmax regression, we can generalize to the following:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "z_j &= \\vec w_j \\cdot \\vec x + b_j\\\\\n",
    "a_j &= \\frac{e^{z_j}}{\\sum_{k=1}^N e^{z_k}} = P(y=j|\\vec x)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The loss function with softmax regression is the following:\n",
    "\n",
    "$$\n",
    "\\text{loss}(a_1,a_2,a_3,...,a_n;y) = -\\log_n \\text{  if } y = n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with Softmax Output\n",
    "\n",
    "Start with specifying the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=25, activation='relu'),\n",
    "    Dense(units=15, activation='relu'),\n",
    "    Dense(units=10, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the loss and the cost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "model.compile(loss=SparseCategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `SparseCategoricalCrossentropy`: target is a number corresponding to index\n",
    "  * i.e. if $n=10$, then $0 \\le y \\le 9$\n",
    "* `CategoricalCrossEntropy`: target is one-hot encoded\n",
    "  * i.e. $y=2$, then you would get back a vector with 0's and a 1 in the index related to $y$\n",
    "\n",
    "Train on data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39mfit(X,Y,epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# code breaks because we haven't defined any data for the model to train on yet\n",
    "model.fit(X,Y,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Improved Implementation of Softmax\n",
    "\n",
    "* We already have some issues with roundoff errors\n",
    "* more numerically accurate implementation of logistic loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Additional NN Conecpts\n",
    "\n",
    "1. Advanced optimization with gradient descent\n",
    "   * $w_j = w_j - \\alpha \\frac{\\partial}{\\partial w_j}J(\\vec w, b)$\n",
    "   * will generate a bunch of contour lines\n",
    "   * to go faster, increase $\\alpha$\n",
    "   * to go slower, decrease $\\alpha$\n",
    "2. Adam algorithm\n",
    "   * faster, the standard choice for ML algorithm\n",
    "   * Adam: adaptive movement estimation (not just one $\\alpha$)\n",
    "   * $w_1 = w_1 - \\alpha_1 \\frac{\\partial}{\\partial w_1}J(\\vec w, b)$\n",
    "   * $w_2 = w_2 - \\alpha_2 \\frac{\\partial}{\\partial w_2}J(\\vec w, b)$\n",
    "   * ...\n",
    "   * $b = b - \\alpha_{n+1} \\frac{\\partial}{\\partial w_1}J(\\vec w, b)$\n",
    "   * if $w_j$ or $b$ keeps moving in the same direction, increase $\\alpha_j$\n",
    "   * if $w_j$ or $b$ keeps oscillating, decrease $\\alpha_j$\n",
    "   * code is the following:\n",
    "\n",
    "```python\n",
    "model.compile(optimizer=tf.keras.optimizer.Adam(learning_rate=1e-3), loss=tf.keras.losses.SparseCtagoricalCrossentropy(from_logits=True))\n",
    "```\n",
    "\n",
    "\n",
    "3. Additional layer types\n",
    "   * Dense layer: Each neuron in a function of **all** the activation outputs of the previous layer\n",
    "   * Convolutional layer: each neuron only looks at part of the previous layers and outputs\n",
    "     * faster computation\n",
    "     * needs less training data, meaning less prone to overfitting\n",
    "    * other types: transformer, attention, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08849f8dffc3f27fb59cf06aefb79cb7a49147ad49564f36fdad5976b28849fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
