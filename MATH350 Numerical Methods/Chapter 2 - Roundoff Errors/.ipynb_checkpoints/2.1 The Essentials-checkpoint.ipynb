{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c260a7e5-d3c0-44e9-9054-c8f3ccafc288",
   "metadata": {},
   "source": [
    "# 2.1: The Essentials\n",
    "\n",
    "This section talks all about the essentials of roundoff errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb34db9-6263-43f7-bc0d-4b711e439e6c",
   "metadata": {},
   "source": [
    "## Computer Representation of Numbers\n",
    "\n",
    "> **FACT:** Any number $x \\in \\mathbb{R}$ can be represented in binary by:\n",
    "> $$\n",
    "     x = \\pm (1.d_1d_2d_3\\cdots) \\cdot 2^e\n",
    "  $$\n",
    "> \n",
    "> where $e$ is an integer exponent (DON'T think like the `exp` function) and $d_1 = 0$ or $1$ and $(1.d_1d_2d_3\\cdots)$ is called the mantissa.\n",
    ">\n",
    "> The value of the mantissa can be converted to denary (base-10) by:\n",
    "> $$\n",
    "    1 + \\frac{d_1}{2} + \\frac{d_2}{2^2} + \\frac{d_3}{2^3} + \\cdots\n",
    "  $$\n",
    "  \n",
    "\n",
    "> #### Example 1: Binary Conversion\n",
    "> \n",
    "> a)\n",
    "> $$\n",
    "    \\begin{aligned}\n",
    "        x &= -(1.101000\\cdots) \\cdot 2^1\\\\\n",
    "        &= -(1 + \\frac{1}{2}+\\frac{1}{8 \\cdot 2\\\\\n",
    "        &= -3.25\n",
    "    \\end{aligned}\n",
    "  $$\n",
    ">  \n",
    "> b)\n",
    "> $$\n",
    "    \\begin{aligned}\n",
    "        x &= -(1.00110100\\cdots) \\cdot 2^6\\\\\n",
    "        &= -(1 + \\frac{1}{8}+\\frac{1}{16}+\\frac{1}{64}) \\cdot 64\\\\\n",
    "        &= 77\n",
    "    \\end{aligned}\n",
    "  $$\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b97adbd-112b-492f-9c19-bf63bd6882a5",
   "metadata": {},
   "source": [
    "## Floating Point Representation\n",
    "\n",
    "In order to store a number on a computer using finite precision (aka a finite number of digits), we convert it to a **floating point representation**, or the approximation of the number stored in memory. We can represent this with $f \\ell (x) \\approx x$. This means that $f\\ell(x) = \\text{ sign}(x) \\cdot (1.\\tilde{d_1}\\tilde{d_2}\\tilde{d_3}\\cdots\\tilde{d_t}) \\cdot 2^e$, where $L \\le e \\le U$. \n",
    "\n",
    "The relative rounding error in the approximation for the floating point representation $f\\ell(x)\\approx x$ may be quantified by $\\frac{\\left|f\\ell(x) - x\\right|}{|x|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723d689e-4353-4002-a657-5a8a363bdc31",
   "metadata": {},
   "source": [
    "## The IEEE Standard\n",
    "\n",
    "The IEEE standard for floating point numbers guarantees that $\\frac{|f\\ell(x) - x|}{|x|} \\le \\frac{1}{2} \\cdot 2^{-t} = 2^{-t+1} = \\eta = \\epsilon_{mach}$. This is the upper bound of the rounding error, which is called either the rounding unit or machine epsilon or unit roundoff.\n",
    "\n",
    "> **IEEE STANDARD:** Double Precision\n",
    ">\n",
    "> In a 64 bit block of computer memory, 1 bit is used for the sign of the number, 11 bits are used for the exponent, and the rest of the 52 bits are for the mantissa.\n",
    "\n",
    "so $\\eta = 2^{-53} \\approx 1.1 \\cdot 10^{-16}$. This is the best that we can expect for the rounding error on average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68c5150-2d3d-4bc2-b008-181523bd353e",
   "metadata": {},
   "source": [
    "## Problems That Can Arise with Floating Point Numbers\n",
    "\n",
    "* undefined errors ($\\frac{0}{0}, 0^0$)\n",
    "* overflow/underflow (#'s that are too big/too small in memory)\n",
    "    * In the IEEE standard for double precision, $e < -1023$, $e > 1024$\n",
    "* cancellation error: large relative error that results when computing $z=x-y$ where $x\\approx y$\n",
    "    * relative error gets big because you divide by $|z| = |x-y|$ which goes in the denominator (so the denomiator is very small)\n",
    "    * Place where this can happen: approximating derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccfec63-d7a3-41ba-a37c-1ff5e2a2468e",
   "metadata": {},
   "source": [
    "## A Script Analyzing the Behavior of Roundoff Error\n",
    "\n",
    "Let's try to approximate a function $f(t)$ at a bunch of $t$ intervals on $[0,1]$ in double and single precision, then comparing the 2 approximations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec339c-788e-4fa1-aa65-43a87b3c97fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%%%%%%%%%%% SETTING UP OUR VARIABLES %%%%%%%%%%%%%%%%\n",
    "t = linspace(0,1,500); % Domain discretization\n",
    "fd = exp(-t) .* cos(10*t); % function approximated in double precision (DEFAULT)\n",
    "fs = single(fd); % function approximation in single precision\n",
    "\n",
    "%%%%%%%% COMPUTE THE RELATIVE ERROR %%%%%%%%%%%%%%%\n",
    "err = (fd - fs) ./ fd; % No abs because we want to observe the sign change, so this is the signed absolute error\n",
    "\n",
    "%%%%%%%%%% PLOTTING THE ERROR %%%%%%%%%%%%%%%%%\n",
    "figure\n",
    "plot(t, err, '*-')\n",
    "xlabel('t')\n",
    "ylabel('error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matlab",
   "language": "matlab",
   "name": "matlab"
  },
  "language_info": {
   "codemirror_mode": "octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "matlab",
   "version": "0.16.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
