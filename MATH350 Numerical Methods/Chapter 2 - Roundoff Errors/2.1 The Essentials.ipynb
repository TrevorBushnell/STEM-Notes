{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c260a7e5-d3c0-44e9-9054-c8f3ccafc288",
   "metadata": {},
   "source": [
    "# 2.1: The Essentials\n",
    "\n",
    "This section talks all about the essentials of roundoff errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb34db9-6263-43f7-bc0d-4b711e439e6c",
   "metadata": {},
   "source": [
    "## Computer Representation of Numbers\n",
    "\n",
    "> **FACT:** Any number $x \\in \\mathbb{R}$ can be represented in binary by:\n",
    "> $$\n",
    "     x = \\pm (1.d_1d_2d_3\\cdots) \\cdot 2^e\n",
    "  $$\n",
    "> \n",
    "> where $e$ is an integer exponent (DON'T think like the `exp` function) and $d_1 = 0$ or $1$ and $(1.d_1d_2d_3\\cdots)$ is called the mantissa.\n",
    ">\n",
    "> The value of the mantissa can be converted to denary (base-10) by:\n",
    "> $$\n",
    "    1 + \\frac{d_1}{2} + \\frac{d_2}{2^2} + \\frac{d_3}{2^3} + \\cdots\n",
    "  $$\n",
    "  \n",
    "\n",
    "> #### Example 1: Binary Conversion\n",
    "> \n",
    "> a)\n",
    "> $$\n",
    "    \\begin{aligned}\n",
    "        x &= -(1.101000\\cdots) \\cdot 2^1\\\\\n",
    "        &= -(1 + \\frac{1}{2}+\\frac{1}{8 \\cdot 2\\\\\n",
    "        &= -3.25\n",
    "    \\end{aligned}\n",
    "  $$\n",
    ">  \n",
    "> b)\n",
    "> $$\n",
    "    \\begin{aligned}\n",
    "        x &= -(1.00110100\\cdots) \\cdot 2^6\\\\\n",
    "        &= -(1 + \\frac{1}{8}+\\frac{1}{16}+\\frac{1}{64}) \\cdot 64\\\\\n",
    "        &= 77\n",
    "    \\end{aligned}\n",
    "  $$\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b97adbd-112b-492f-9c19-bf63bd6882a5",
   "metadata": {},
   "source": [
    "## Floating Point Representation\n",
    "\n",
    "In order to store a number on a computer using finite precision (aka a finite number of digits), we convert it to a **floating point representation**, or the approximation of the number stored in memory. We can represent this with $f \\ell (x) \\approx x$. This means that $f\\ell(x) = \\text{ sign}(x) \\cdot (1.\\tilde{d_1}\\tilde{d_2}\\tilde{d_3}\\cdots\\tilde{d_t}) \\cdot 2^e$, where $L \\le e \\le U$. \n",
    "\n",
    "The relative rounding error in the approximation for the floating point representation $f\\ell(x)\\approx x$ may be quantified by $\\frac{\\left|f\\ell(x) - x\\right|}{|x|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723d689e-4353-4002-a657-5a8a363bdc31",
   "metadata": {},
   "source": [
    "## The IEEE Standard\n",
    "\n",
    "The IEEE standard for floating point numbers guarantees that $$\\frac{\\left|f\\ell(x) - x\\right|}{|x|} \\le \\frac[1}{2} \\cdot 2^{-t} = 2^{-t+1} = \\eta = \\epsilon_{mach}$$. This is the upper bound of the rounding error, which is called either the rounding unit or machine epsilon or unit roundoff.\n",
    "\n",
    "> **IEEE STANDARD:** Double Precision\n",
    ">\n",
    "> In a 64 bit block of computer memory, 1 bit is used for the sign of the number, 11 bits are used for the exponent, and the rest of the 52 bits are for the mantissa.\n",
    "\n",
    "so $\\eta = 2^{-53} \\approx 1.1 \\cdot 10^{-16}$. This is the best that we can expect for the rounding error on average."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matlab",
   "language": "matlab",
   "name": "matlab"
  },
  "language_info": {
   "codemirror_mode": "octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "matlab",
   "version": "0.16.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
